{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "from datasets.shapenet_data_pc import ShapeNet15kPointClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataroot, npoints,category):\n",
    "    tr_dataset = ShapeNet15kPointClouds(root_dir=dataroot,\n",
    "        categories=category.split(','), split='train',\n",
    "        tr_sample_size=npoints,\n",
    "        te_sample_size=npoints,\n",
    "        scale=1.,\n",
    "        normalize_per_shape=False,\n",
    "        normalize_std_per_axis=False,\n",
    "        random_subsample=True)\n",
    "    te_dataset = ShapeNet15kPointClouds(root_dir=dataroot,\n",
    "        categories=category.split(','), split='val',\n",
    "        tr_sample_size=npoints,\n",
    "        te_sample_size=npoints,\n",
    "        scale=1.,\n",
    "        normalize_per_shape=False,\n",
    "        normalize_std_per_axis=False,\n",
    "        all_points_mean=tr_dataset.all_points_mean,\n",
    "        all_points_std=tr_dataset.all_points_std,\n",
    "    )\n",
    "    return tr_dataset, te_dataset\n",
    "\n",
    "def get_dataloader(train_dataset, test_dataset=None):\n",
    "\n",
    "    # if opt.distribution_type == 'multi':\n",
    "    #     train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    #         train_dataset,\n",
    "    #         num_replicas=opt.world_size,\n",
    "    #         rank=opt.rank\n",
    "    #     )\n",
    "    #     if test_dataset is not None:\n",
    "    #         test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    #             test_dataset,\n",
    "    #             num_replicas=opt.world_size,\n",
    "    #             rank=opt.rank\n",
    "    #         )\n",
    "    #     else:\n",
    "    #         test_sampler = None\n",
    "    # else:\n",
    "    train_sampler = None\n",
    "    test_sampler = None\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1,sampler=train_sampler,\n",
    "                                                   shuffle=train_sampler is None, num_workers=1, drop_last=True)\n",
    "\n",
    "    if test_dataset is not None:\n",
    "        test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1,sampler=test_sampler,\n",
    "                                                   shuffle=False, num_workers=1, drop_last=False)\n",
    "    else:\n",
    "        test_dataloader = None\n",
    "\n",
    "    return train_dataloader, test_dataloader, train_sampler, test_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data:4612\n",
      "Min number of points: (train)2048 (test)2048\n",
      "Total number of data:662\n",
      "Min number of points: (train)2048 (test)2048\n",
      "4612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataroot = \"/home/yifan/studium/3D_Completion/DiT-3D_2024AILab/datasets/data/ShapeNetCore.v2.PC15k\"\n",
    "npoints = 2048\n",
    "category = \"chair\"\n",
    "\n",
    "train_dataset, _ = get_dataset(dataroot, npoints, category)\n",
    "dataloader, _, train_sampler, _ = get_dataloader(train_dataset, None)\n",
    "print(len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "dict_keys(['idx', 'train_points', 'test_points', 'mean', 'std', 'cate_idx', 'sid', 'mid'])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "print(len(batch))\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4524])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 3])\n"
     ]
    }
   ],
   "source": [
    "print(batch['train_points'].shape) # batch, num_points, xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(batch['train_points'].transpose(1,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "print(batch['cate_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original pcd shape: (15000, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "point_cloud = np.load('/home/yifan/studium/3D_Completion/DiT-3D_2024AILab/datasets/data/ShapeNetCore.v2.PC15k/02801938/test/2bcc1b8bf5ac9ddc97e30bfe57d923fb.npy')\n",
    "\n",
    "print(\"original pcd shape:\", point_cloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "  (x_embedder): PatchEmbed_Voxel(\n",
       "    (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(2, 384)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=2304, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model forward test\n",
    "\n",
    "from models.dit3d import DiT3D_models\n",
    "model = DiT3D_models['DiT-S/4']()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "  (x_embedder): PatchEmbed_Voxel(\n",
       "    (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(2, 384)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=2304, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case for model with adaptformer, DiT-S/4\n",
    "from models.dit3d import DiT3D_models, DiT\n",
    "\n",
    "model = DiT(depth=12, hidden_size=384, patch_size=4, num_heads=6)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "  (x_embedder): PatchEmbed_Voxel(\n",
       "    (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(2, 384)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=2304, bias=True)\n",
       "      )\n",
       "      (adaptmlp): Adapter(\n",
       "        (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (down_proj): Linear(in_features=384, out_features=64, bias=True)\n",
       "        (non_linear_func): ReLU()\n",
       "        (up_proj): Linear(in_features=64, out_features=384, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.dit3d import DiT3D_models, DiT\n",
    "model_adaptformer = DiT(depth=12, hidden_size=384, patch_size=4, num_heads=6, adaptformer=True)\n",
    "model_adaptformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3839,  0.9537,  0.7609,  ...,  0.0210,  0.9074, -0.3622],\n",
      "         [ 0.4203, -0.1210,  0.3230,  ...,  0.0515, -1.6827,  0.5799],\n",
      "         [-1.2297,  0.3981,  1.8440,  ..., -0.4590, -0.1731, -0.3693]]],\n",
      "       device='cuda:0')\n",
      "tensor([488], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# input random tensot to check shape\n",
    "x = torch.randn(1, 3, 2048).to('cuda')\n",
    "t = torch.randint(1, 1001, (1,)).to('cuda')\n",
    "y = torch.randint(0, 1, (1,)).to('cuda')\n",
    "model = model.to('cuda')\n",
    "print(x)\n",
    "print(t)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x after voxelization:  torch.Size([1, 3, 32, 32, 32])\n",
      "voxel_coords:  torch.Size([1, 3, 2048])\n",
      "x after patchfiy:  torch.Size([1, 512, 384])\n",
      "x after add position embedding:  torch.Size([1, 512, 384])\n",
      "time embedding:  torch.Size([1, 384])\n",
      "label embedding:  torch.Size([1, 384])\n",
      "x after dit block: torch.Size([1, 512, 384])\n",
      "x after final layer:  torch.Size([1, 512, 192])\n",
      "x after unpatchify:  torch.Size([1, 3, 32, 32, 32])\n",
      "x after devoxelization:  torch.Size([1, 3, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2048])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(x, t, y)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiT_S_4 with out adapter trainable parameters:  32610624\n",
      "DiT_S_4 with out adapter total parameters:  32807232\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"DiT_S_4 with out adapter trainable parameters: \", trainable_params)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"DiT_S_4 with out adapter total parameters: \", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiT_S_4 with out adapter trainable parameters:  33215040\n",
      "DiT_S_4 with out adapter total parameters:  33411648\n"
     ]
    }
   ],
   "source": [
    "trainable_params_adapt = sum(p.numel() for p in model_adaptformer.parameters() if p.requires_grad)\n",
    "print(\"DiT_S_4 with out adapter trainable parameters: \", trainable_params_adapt)\n",
    "total_params_adapt = sum(p.numel() for p in model_adaptformer.parameters())\n",
    "print(\"DiT_S_4 with out adapter total parameters: \", total_params_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604416"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params = trainable_params_adapt - trainable_params\n",
    "trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size: 8\n"
     ]
    }
   ],
   "source": [
    "# check Partial Pcd embedding layer\n",
    "from models.dit3d import PartialPcdEmbedder\n",
    "import torch\n",
    "y_embedder = PartialPcdEmbedder(0.1,\n",
    "                                hidden_size=384,\n",
    "                                patch_size=4,\n",
    "                                in_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 300])\n"
     ]
    }
   ],
   "source": [
    "# input random tensor to check shape\n",
    "partial_pcd = torch.randn(1, 3, 300).to('cuda')\n",
    "y_embedder = y_embedder.to('cuda')\n",
    "print(partial_pcd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = y_embedder(partial_pcd, True)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "  (x_embedder): PatchEmbed_Voxel(\n",
       "    (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (partial_pcd_embedder): PartialPcdEmbedder(\n",
       "    (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "    (x_embedder): PatchEmbed_Voxel(\n",
       "      (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-2): 3 x ViTBlock(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=2304, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check DiT with partial point cloud condtion\n",
    "from models.dit3d import DiT3D_models, DiT\n",
    "model_partial_pcd = DiT(depth=12, hidden_size=384, patch_size=4, num_heads=6, adaptformer=False, partial_pcd=True)\n",
    "model_partial_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2048])\n",
      "tensor([300], device='cuda:0')\n",
      "torch.Size([1, 3, 300])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# input random tensot to check shape\n",
    "x = torch.randn(1, 3, 2048).to('cuda')\n",
    "t = torch.randint(1, 1001, (1,)).to('cuda')\n",
    "partial_pcd = torch.randn(1, 3, 300).to('cuda')\n",
    "model_partial_pcd = model_partial_pcd.to('cuda')\n",
    "print(x.shape)\n",
    "print(t)\n",
    "print(partial_pcd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_partial_pcd(x, t, partial_pcd)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda-11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
