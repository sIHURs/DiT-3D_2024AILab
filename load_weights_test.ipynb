{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model S4 with out adapter and use label embedder weight keys\n",
      "len:  132\n",
      "pos_embed\n",
      "x_embedder.proj.weight\n",
      "x_embedder.proj.bias\n",
      "t_embedder.mlp.0.weight\n",
      "t_embedder.mlp.0.bias\n",
      "t_embedder.mlp.2.weight\n",
      "t_embedder.mlp.2.bias\n",
      "y_embedder.embedding_table.weight\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.0.adaLN_modulation.1.weight\n",
      "blocks.0.adaLN_modulation.1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.1.adaLN_modulation.1.weight\n",
      "blocks.1.adaLN_modulation.1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.2.adaLN_modulation.1.weight\n",
      "blocks.2.adaLN_modulation.1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.3.adaLN_modulation.1.weight\n",
      "blocks.3.adaLN_modulation.1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.4.adaLN_modulation.1.weight\n",
      "blocks.4.adaLN_modulation.1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.5.adaLN_modulation.1.weight\n",
      "blocks.5.adaLN_modulation.1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.6.adaLN_modulation.1.weight\n",
      "blocks.6.adaLN_modulation.1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.7.adaLN_modulation.1.weight\n",
      "blocks.7.adaLN_modulation.1.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.8.adaLN_modulation.1.weight\n",
      "blocks.8.adaLN_modulation.1.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.9.adaLN_modulation.1.weight\n",
      "blocks.9.adaLN_modulation.1.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.10.adaLN_modulation.1.weight\n",
      "blocks.10.adaLN_modulation.1.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "blocks.11.adaLN_modulation.1.weight\n",
      "blocks.11.adaLN_modulation.1.bias\n",
      "final_layer.linear.weight\n",
      "final_layer.linear.bias\n",
      "final_layer.adaLN_modulation.1.weight\n",
      "final_layer.adaLN_modulation.1.bias\n"
     ]
    }
   ],
   "source": [
    "# first to see the trainable parameter of dit model here we use Dit S4\n",
    "model_S4 = DiT(depth=12, hidden_size=384, patch_size=4, num_heads=6)\n",
    "model_S4_keys = model_S4.state_dict().keys()\n",
    "print(\"model S4 with out adapter and use label embedder weight keys\")\n",
    "print(\"len: \", len(model_S4_keys))\n",
    "for key in model_S4_keys:\n",
    "\tprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model S4 with adapter and use label embedder weight keys\n",
      "ken:  204\n",
      "pos_embed\n",
      "x_embedder.proj.weight\n",
      "x_embedder.proj.bias\n",
      "t_embedder.mlp.0.weight\n",
      "t_embedder.mlp.0.bias\n",
      "t_embedder.mlp.2.weight\n",
      "t_embedder.mlp.2.bias\n",
      "y_embedder.embedding_table.weight\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.0.adaLN_modulation.1.weight\n",
      "blocks.0.adaLN_modulation.1.bias\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.0.adaptmlp.down_proj.weight\n",
      "blocks.0.adaptmlp.down_proj.bias\n",
      "blocks.0.adaptmlp.up_proj.weight\n",
      "blocks.0.adaptmlp.up_proj.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.1.adaLN_modulation.1.weight\n",
      "blocks.1.adaLN_modulation.1.bias\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.1.adaptmlp.down_proj.weight\n",
      "blocks.1.adaptmlp.down_proj.bias\n",
      "blocks.1.adaptmlp.up_proj.weight\n",
      "blocks.1.adaptmlp.up_proj.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.2.adaLN_modulation.1.weight\n",
      "blocks.2.adaLN_modulation.1.bias\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.2.adaptmlp.down_proj.weight\n",
      "blocks.2.adaptmlp.down_proj.bias\n",
      "blocks.2.adaptmlp.up_proj.weight\n",
      "blocks.2.adaptmlp.up_proj.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.3.adaLN_modulation.1.weight\n",
      "blocks.3.adaLN_modulation.1.bias\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.3.adaptmlp.down_proj.weight\n",
      "blocks.3.adaptmlp.down_proj.bias\n",
      "blocks.3.adaptmlp.up_proj.weight\n",
      "blocks.3.adaptmlp.up_proj.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.4.adaLN_modulation.1.weight\n",
      "blocks.4.adaLN_modulation.1.bias\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.4.adaptmlp.down_proj.weight\n",
      "blocks.4.adaptmlp.down_proj.bias\n",
      "blocks.4.adaptmlp.up_proj.weight\n",
      "blocks.4.adaptmlp.up_proj.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.5.adaLN_modulation.1.weight\n",
      "blocks.5.adaLN_modulation.1.bias\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.5.adaptmlp.down_proj.weight\n",
      "blocks.5.adaptmlp.down_proj.bias\n",
      "blocks.5.adaptmlp.up_proj.weight\n",
      "blocks.5.adaptmlp.up_proj.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.6.adaLN_modulation.1.weight\n",
      "blocks.6.adaLN_modulation.1.bias\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.6.adaptmlp.down_proj.weight\n",
      "blocks.6.adaptmlp.down_proj.bias\n",
      "blocks.6.adaptmlp.up_proj.weight\n",
      "blocks.6.adaptmlp.up_proj.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.7.adaLN_modulation.1.weight\n",
      "blocks.7.adaLN_modulation.1.bias\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.7.adaptmlp.down_proj.weight\n",
      "blocks.7.adaptmlp.down_proj.bias\n",
      "blocks.7.adaptmlp.up_proj.weight\n",
      "blocks.7.adaptmlp.up_proj.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.8.adaLN_modulation.1.weight\n",
      "blocks.8.adaLN_modulation.1.bias\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.8.adaptmlp.down_proj.weight\n",
      "blocks.8.adaptmlp.down_proj.bias\n",
      "blocks.8.adaptmlp.up_proj.weight\n",
      "blocks.8.adaptmlp.up_proj.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.9.adaLN_modulation.1.weight\n",
      "blocks.9.adaLN_modulation.1.bias\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.9.adaptmlp.down_proj.weight\n",
      "blocks.9.adaptmlp.down_proj.bias\n",
      "blocks.9.adaptmlp.up_proj.weight\n",
      "blocks.9.adaptmlp.up_proj.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.10.adaLN_modulation.1.weight\n",
      "blocks.10.adaLN_modulation.1.bias\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.10.adaptmlp.down_proj.weight\n",
      "blocks.10.adaptmlp.down_proj.bias\n",
      "blocks.10.adaptmlp.up_proj.weight\n",
      "blocks.10.adaptmlp.up_proj.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "blocks.11.adaLN_modulation.1.weight\n",
      "blocks.11.adaLN_modulation.1.bias\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.11.adaptmlp.down_proj.weight\n",
      "blocks.11.adaptmlp.down_proj.bias\n",
      "blocks.11.adaptmlp.up_proj.weight\n",
      "blocks.11.adaptmlp.up_proj.bias\n",
      "final_layer.linear.weight\n",
      "final_layer.linear.bias\n",
      "final_layer.adaLN_modulation.1.weight\n",
      "final_layer.adaLN_modulation.1.bias\n"
     ]
    }
   ],
   "source": [
    "model_S4_adapt = DiT(depth=12, hidden_size=384, patch_size=4, num_heads=6, adaptformer=True)\n",
    "model_S4_adapt_keys = model_S4_adapt.state_dict().keys()\n",
    "print(\"model S4 with adapter and use label embedder weight keys\")\n",
    "print(\"ken: \", len(model_S4_adapt_keys))\n",
    "for key in model_S4_adapt_keys:\n",
    "\tprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model S4 with adapter and use partial pcd embedder weight keys\n",
      "len:  230\n",
      "pos_embed\n",
      "x_embedder.proj.weight\n",
      "x_embedder.proj.bias\n",
      "t_embedder.mlp.0.weight\n",
      "t_embedder.mlp.0.bias\n",
      "t_embedder.mlp.2.weight\n",
      "t_embedder.mlp.2.bias\n",
      "partial_pcd_embedder.pos_embed\n",
      "partial_pcd_embedder.x_embedder.proj.weight\n",
      "partial_pcd_embedder.x_embedder.proj.bias\n",
      "partial_pcd_embedder.blocks.0.attn.qkv.weight\n",
      "partial_pcd_embedder.blocks.0.attn.qkv.bias\n",
      "partial_pcd_embedder.blocks.0.attn.proj.weight\n",
      "partial_pcd_embedder.blocks.0.attn.proj.bias\n",
      "partial_pcd_embedder.blocks.0.mlp.fc1.weight\n",
      "partial_pcd_embedder.blocks.0.mlp.fc1.bias\n",
      "partial_pcd_embedder.blocks.0.mlp.fc2.weight\n",
      "partial_pcd_embedder.blocks.0.mlp.fc2.bias\n",
      "partial_pcd_embedder.blocks.1.attn.qkv.weight\n",
      "partial_pcd_embedder.blocks.1.attn.qkv.bias\n",
      "partial_pcd_embedder.blocks.1.attn.proj.weight\n",
      "partial_pcd_embedder.blocks.1.attn.proj.bias\n",
      "partial_pcd_embedder.blocks.1.mlp.fc1.weight\n",
      "partial_pcd_embedder.blocks.1.mlp.fc1.bias\n",
      "partial_pcd_embedder.blocks.1.mlp.fc2.weight\n",
      "partial_pcd_embedder.blocks.1.mlp.fc2.bias\n",
      "partial_pcd_embedder.blocks.2.attn.qkv.weight\n",
      "partial_pcd_embedder.blocks.2.attn.qkv.bias\n",
      "partial_pcd_embedder.blocks.2.attn.proj.weight\n",
      "partial_pcd_embedder.blocks.2.attn.proj.bias\n",
      "partial_pcd_embedder.blocks.2.mlp.fc1.weight\n",
      "partial_pcd_embedder.blocks.2.mlp.fc1.bias\n",
      "partial_pcd_embedder.blocks.2.mlp.fc2.weight\n",
      "partial_pcd_embedder.blocks.2.mlp.fc2.bias\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.0.adaLN_modulation.1.weight\n",
      "blocks.0.adaLN_modulation.1.bias\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.0.adaptmlp.down_proj.weight\n",
      "blocks.0.adaptmlp.down_proj.bias\n",
      "blocks.0.adaptmlp.up_proj.weight\n",
      "blocks.0.adaptmlp.up_proj.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.1.adaLN_modulation.1.weight\n",
      "blocks.1.adaLN_modulation.1.bias\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.1.adaptmlp.down_proj.weight\n",
      "blocks.1.adaptmlp.down_proj.bias\n",
      "blocks.1.adaptmlp.up_proj.weight\n",
      "blocks.1.adaptmlp.up_proj.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.2.adaLN_modulation.1.weight\n",
      "blocks.2.adaLN_modulation.1.bias\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.2.adaptmlp.down_proj.weight\n",
      "blocks.2.adaptmlp.down_proj.bias\n",
      "blocks.2.adaptmlp.up_proj.weight\n",
      "blocks.2.adaptmlp.up_proj.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.3.adaLN_modulation.1.weight\n",
      "blocks.3.adaLN_modulation.1.bias\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.3.adaptmlp.down_proj.weight\n",
      "blocks.3.adaptmlp.down_proj.bias\n",
      "blocks.3.adaptmlp.up_proj.weight\n",
      "blocks.3.adaptmlp.up_proj.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.4.adaLN_modulation.1.weight\n",
      "blocks.4.adaLN_modulation.1.bias\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.4.adaptmlp.down_proj.weight\n",
      "blocks.4.adaptmlp.down_proj.bias\n",
      "blocks.4.adaptmlp.up_proj.weight\n",
      "blocks.4.adaptmlp.up_proj.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.5.adaLN_modulation.1.weight\n",
      "blocks.5.adaLN_modulation.1.bias\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.5.adaptmlp.down_proj.weight\n",
      "blocks.5.adaptmlp.down_proj.bias\n",
      "blocks.5.adaptmlp.up_proj.weight\n",
      "blocks.5.adaptmlp.up_proj.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.6.adaLN_modulation.1.weight\n",
      "blocks.6.adaLN_modulation.1.bias\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.6.adaptmlp.down_proj.weight\n",
      "blocks.6.adaptmlp.down_proj.bias\n",
      "blocks.6.adaptmlp.up_proj.weight\n",
      "blocks.6.adaptmlp.up_proj.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.7.adaLN_modulation.1.weight\n",
      "blocks.7.adaLN_modulation.1.bias\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.7.adaptmlp.down_proj.weight\n",
      "blocks.7.adaptmlp.down_proj.bias\n",
      "blocks.7.adaptmlp.up_proj.weight\n",
      "blocks.7.adaptmlp.up_proj.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.8.adaLN_modulation.1.weight\n",
      "blocks.8.adaLN_modulation.1.bias\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.8.adaptmlp.down_proj.weight\n",
      "blocks.8.adaptmlp.down_proj.bias\n",
      "blocks.8.adaptmlp.up_proj.weight\n",
      "blocks.8.adaptmlp.up_proj.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.9.adaLN_modulation.1.weight\n",
      "blocks.9.adaLN_modulation.1.bias\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.9.adaptmlp.down_proj.weight\n",
      "blocks.9.adaptmlp.down_proj.bias\n",
      "blocks.9.adaptmlp.up_proj.weight\n",
      "blocks.9.adaptmlp.up_proj.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.10.adaLN_modulation.1.weight\n",
      "blocks.10.adaLN_modulation.1.bias\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.10.adaptmlp.down_proj.weight\n",
      "blocks.10.adaptmlp.down_proj.bias\n",
      "blocks.10.adaptmlp.up_proj.weight\n",
      "blocks.10.adaptmlp.up_proj.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "blocks.11.adaLN_modulation.1.weight\n",
      "blocks.11.adaLN_modulation.1.bias\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.weight\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.bias\n",
      "blocks.11.adaptmlp.down_proj.weight\n",
      "blocks.11.adaptmlp.down_proj.bias\n",
      "blocks.11.adaptmlp.up_proj.weight\n",
      "blocks.11.adaptmlp.up_proj.bias\n",
      "final_layer.linear.weight\n",
      "final_layer.linear.bias\n",
      "final_layer.adaLN_modulation.1.weight\n",
      "final_layer.adaLN_modulation.1.bias\n"
     ]
    }
   ],
   "source": [
    "model_S4_partial_pcd = DiT(depth=12, hidden_size=384, patch_size=4, num_heads=6, adaptformer=True, partial_pcd=True)\n",
    "model_S4_adapt_partial_pcd_keys = model_S4_partial_pcd.state_dict().keys()\n",
    "print(\"model S4 with adapter and use partial pcd embedder weight keys\")\n",
    "print(\"len: \", len(model_S4_adapt_partial_pcd_keys))\n",
    "for key in model_S4_adapt_partial_pcd_keys:\n",
    "\tprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained weight keys\n",
      "len:  132\n",
      "model.module.pos_embed\n",
      "model.module.x_embedder.proj.weight\n",
      "model.module.x_embedder.proj.bias\n",
      "model.module.t_embedder.mlp.0.weight\n",
      "model.module.t_embedder.mlp.0.bias\n",
      "model.module.t_embedder.mlp.2.weight\n",
      "model.module.t_embedder.mlp.2.bias\n",
      "model.module.y_embedder.embedding_table.weight\n",
      "model.module.blocks.0.attn.qkv.weight\n",
      "model.module.blocks.0.attn.qkv.bias\n",
      "model.module.blocks.0.attn.proj.weight\n",
      "model.module.blocks.0.attn.proj.bias\n",
      "model.module.blocks.0.mlp.fc1.weight\n",
      "model.module.blocks.0.mlp.fc1.bias\n",
      "model.module.blocks.0.mlp.fc2.weight\n",
      "model.module.blocks.0.mlp.fc2.bias\n",
      "model.module.blocks.0.adaLN_modulation.1.weight\n",
      "model.module.blocks.0.adaLN_modulation.1.bias\n",
      "model.module.blocks.1.attn.qkv.weight\n",
      "model.module.blocks.1.attn.qkv.bias\n",
      "model.module.blocks.1.attn.proj.weight\n",
      "model.module.blocks.1.attn.proj.bias\n",
      "model.module.blocks.1.mlp.fc1.weight\n",
      "model.module.blocks.1.mlp.fc1.bias\n",
      "model.module.blocks.1.mlp.fc2.weight\n",
      "model.module.blocks.1.mlp.fc2.bias\n",
      "model.module.blocks.1.adaLN_modulation.1.weight\n",
      "model.module.blocks.1.adaLN_modulation.1.bias\n",
      "model.module.blocks.2.attn.qkv.weight\n",
      "model.module.blocks.2.attn.qkv.bias\n",
      "model.module.blocks.2.attn.proj.weight\n",
      "model.module.blocks.2.attn.proj.bias\n",
      "model.module.blocks.2.mlp.fc1.weight\n",
      "model.module.blocks.2.mlp.fc1.bias\n",
      "model.module.blocks.2.mlp.fc2.weight\n",
      "model.module.blocks.2.mlp.fc2.bias\n",
      "model.module.blocks.2.adaLN_modulation.1.weight\n",
      "model.module.blocks.2.adaLN_modulation.1.bias\n",
      "model.module.blocks.3.attn.qkv.weight\n",
      "model.module.blocks.3.attn.qkv.bias\n",
      "model.module.blocks.3.attn.proj.weight\n",
      "model.module.blocks.3.attn.proj.bias\n",
      "model.module.blocks.3.mlp.fc1.weight\n",
      "model.module.blocks.3.mlp.fc1.bias\n",
      "model.module.blocks.3.mlp.fc2.weight\n",
      "model.module.blocks.3.mlp.fc2.bias\n",
      "model.module.blocks.3.adaLN_modulation.1.weight\n",
      "model.module.blocks.3.adaLN_modulation.1.bias\n",
      "model.module.blocks.4.attn.qkv.weight\n",
      "model.module.blocks.4.attn.qkv.bias\n",
      "model.module.blocks.4.attn.proj.weight\n",
      "model.module.blocks.4.attn.proj.bias\n",
      "model.module.blocks.4.mlp.fc1.weight\n",
      "model.module.blocks.4.mlp.fc1.bias\n",
      "model.module.blocks.4.mlp.fc2.weight\n",
      "model.module.blocks.4.mlp.fc2.bias\n",
      "model.module.blocks.4.adaLN_modulation.1.weight\n",
      "model.module.blocks.4.adaLN_modulation.1.bias\n",
      "model.module.blocks.5.attn.qkv.weight\n",
      "model.module.blocks.5.attn.qkv.bias\n",
      "model.module.blocks.5.attn.proj.weight\n",
      "model.module.blocks.5.attn.proj.bias\n",
      "model.module.blocks.5.mlp.fc1.weight\n",
      "model.module.blocks.5.mlp.fc1.bias\n",
      "model.module.blocks.5.mlp.fc2.weight\n",
      "model.module.blocks.5.mlp.fc2.bias\n",
      "model.module.blocks.5.adaLN_modulation.1.weight\n",
      "model.module.blocks.5.adaLN_modulation.1.bias\n",
      "model.module.blocks.6.attn.qkv.weight\n",
      "model.module.blocks.6.attn.qkv.bias\n",
      "model.module.blocks.6.attn.proj.weight\n",
      "model.module.blocks.6.attn.proj.bias\n",
      "model.module.blocks.6.mlp.fc1.weight\n",
      "model.module.blocks.6.mlp.fc1.bias\n",
      "model.module.blocks.6.mlp.fc2.weight\n",
      "model.module.blocks.6.mlp.fc2.bias\n",
      "model.module.blocks.6.adaLN_modulation.1.weight\n",
      "model.module.blocks.6.adaLN_modulation.1.bias\n",
      "model.module.blocks.7.attn.qkv.weight\n",
      "model.module.blocks.7.attn.qkv.bias\n",
      "model.module.blocks.7.attn.proj.weight\n",
      "model.module.blocks.7.attn.proj.bias\n",
      "model.module.blocks.7.mlp.fc1.weight\n",
      "model.module.blocks.7.mlp.fc1.bias\n",
      "model.module.blocks.7.mlp.fc2.weight\n",
      "model.module.blocks.7.mlp.fc2.bias\n",
      "model.module.blocks.7.adaLN_modulation.1.weight\n",
      "model.module.blocks.7.adaLN_modulation.1.bias\n",
      "model.module.blocks.8.attn.qkv.weight\n",
      "model.module.blocks.8.attn.qkv.bias\n",
      "model.module.blocks.8.attn.proj.weight\n",
      "model.module.blocks.8.attn.proj.bias\n",
      "model.module.blocks.8.mlp.fc1.weight\n",
      "model.module.blocks.8.mlp.fc1.bias\n",
      "model.module.blocks.8.mlp.fc2.weight\n",
      "model.module.blocks.8.mlp.fc2.bias\n",
      "model.module.blocks.8.adaLN_modulation.1.weight\n",
      "model.module.blocks.8.adaLN_modulation.1.bias\n",
      "model.module.blocks.9.attn.qkv.weight\n",
      "model.module.blocks.9.attn.qkv.bias\n",
      "model.module.blocks.9.attn.proj.weight\n",
      "model.module.blocks.9.attn.proj.bias\n",
      "model.module.blocks.9.mlp.fc1.weight\n",
      "model.module.blocks.9.mlp.fc1.bias\n",
      "model.module.blocks.9.mlp.fc2.weight\n",
      "model.module.blocks.9.mlp.fc2.bias\n",
      "model.module.blocks.9.adaLN_modulation.1.weight\n",
      "model.module.blocks.9.adaLN_modulation.1.bias\n",
      "model.module.blocks.10.attn.qkv.weight\n",
      "model.module.blocks.10.attn.qkv.bias\n",
      "model.module.blocks.10.attn.proj.weight\n",
      "model.module.blocks.10.attn.proj.bias\n",
      "model.module.blocks.10.mlp.fc1.weight\n",
      "model.module.blocks.10.mlp.fc1.bias\n",
      "model.module.blocks.10.mlp.fc2.weight\n",
      "model.module.blocks.10.mlp.fc2.bias\n",
      "model.module.blocks.10.adaLN_modulation.1.weight\n",
      "model.module.blocks.10.adaLN_modulation.1.bias\n",
      "model.module.blocks.11.attn.qkv.weight\n",
      "model.module.blocks.11.attn.qkv.bias\n",
      "model.module.blocks.11.attn.proj.weight\n",
      "model.module.blocks.11.attn.proj.bias\n",
      "model.module.blocks.11.mlp.fc1.weight\n",
      "model.module.blocks.11.mlp.fc1.bias\n",
      "model.module.blocks.11.mlp.fc2.weight\n",
      "model.module.blocks.11.mlp.fc2.bias\n",
      "model.module.blocks.11.adaLN_modulation.1.weight\n",
      "model.module.blocks.11.adaLN_modulation.1.bias\n",
      "model.module.final_layer.linear.weight\n",
      "model.module.final_layer.linear.bias\n",
      "model.module.final_layer.adaLN_modulation.1.weight\n",
      "model.module.final_layer.adaLN_modulation.1.bias\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights_paths = \"checkpoints/checkpoint.pth\"\n",
    "state_dict = torch.load(pretrained_weights_paths)\n",
    "\n",
    "pretrained_keys = state_dict['model_state'].keys()\n",
    "print(\"pretrained weight keys\")\n",
    "print(\"len: \", len(pretrained_keys))\n",
    "for key in pretrained_keys:\n",
    "\tprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if \n",
    "pretrained_weights_paths = \"checkpoints/checkpoint.pth\"\n",
    "ckpt = torch.load(pretrained_weights_paths)\n",
    "ckpt = ckpt['model_state']\n",
    "\n",
    "# have to skip \n",
    "# blocks.n.adaLN_modulation.1.weight\n",
    "# blocks.n.adaLN_modulation.1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts:  132\n",
      "the number of loaded in layer:  106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_S4_dict = model_S4.state_dict()\n",
    "# pretrained_dict = {k: v for k, v in ckpt.items() if k in model_S4_dict and (v.shape == model_S4_dict[k].shape)}\n",
    "\n",
    "count = 0\n",
    "\n",
    "pretrained_dict = {}\n",
    "for k, v in ckpt.items():\n",
    "    count += 1\n",
    "    if k.replace('model.module.','') in model_S4if 'adaLN_modulation.1.weight' in k or 'adaLN_modulation.1.bias' in k:\n",
    "            continue_dict and (v.shape == model_S4_dict[k.replace('model.module.','')].shape):\n",
    "        \n",
    "        pretrained_dict[k] = v\n",
    "    \n",
    "\n",
    "print(\"counts: \", count)\n",
    "print(\"the number of loaded in layer: \", len(pretrained_dict))\n",
    "# model_S4_dict.update(pretrained_dict)\n",
    "# model_S4.load_state_dict(model_S4_dict, strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts:  132\n",
      "the number of loaded in layer:  132\n"
     ]
    }
   ],
   "source": [
    "model_S4_adapt_dict = model_S4_adapt.state_dict()\n",
    "\n",
    "count = 0\n",
    "\n",
    "pretrained_dict = {}\n",
    "for k, v in ckpt.items():\n",
    "    if k.replace('model.module.','') in model_S4_adapt_dict and (v.shape == model_S4_adapt_dict[k.replace('model.module.','')].shape):\n",
    "        if 'adaLN_modulation.1.weight' in k or 'adaLN_modulation.1.bias' in k:\n",
    "            continue\n",
    "        pretrained_dict[k] = v\n",
    "    count += 1\n",
    "print(\"counts: \", count)\n",
    "print(\"the number of loaded in layer: \", len(pretrained_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S4_partial_pcd_dict = model_S4_partial_pcd.state_dict()\n",
    "\n",
    "count = 0\n",
    "\n",
    "pretrained_dict = {}\n",
    "for k, v in ckpt.items():\n",
    "    if k.replace('model.module.','') in model_S4_partial_pcd_dict and (v.shape == model_S4_partial_pcd_dict[k.replace('model.module.','')].shape):\n",
    "        if 'adaLN_modulation.1.weight' in k or 'adaLN_modulation.1.bias' in k:\n",
    "            continue\n",
    "        pretrained_dict[k] = v\n",
    "    count += 1\n",
    "print(\"counts: \", count)\n",
    "print(\"the number of loaded in layer: \", len(pretrained_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_embed: torch.Size([1, 512, 384])\n",
      "x_embedder.proj.weight: torch.Size([384, 3, 4, 4, 4])\n",
      "x_embedder.proj.bias: torch.Size([384])\n",
      "t_embedder.mlp.0.weight: torch.Size([384, 256])\n",
      "t_embedder.mlp.0.bias: torch.Size([384])\n",
      "t_embedder.mlp.2.weight: torch.Size([384, 384])\n",
      "t_embedder.mlp.2.bias: torch.Size([384])\n",
      "partial_pcd_embedder.pos_embed: torch.Size([1, 512, 384])\n",
      "partial_pcd_embedder.x_embedder.proj.weight: torch.Size([384, 3, 4, 4, 4])\n",
      "partial_pcd_embedder.x_embedder.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.0.attn.qkv.weight: torch.Size([1152, 384])\n",
      "partial_pcd_embedder.blocks.0.attn.qkv.bias: torch.Size([1152])\n",
      "partial_pcd_embedder.blocks.0.attn.proj.weight: torch.Size([384, 384])\n",
      "partial_pcd_embedder.blocks.0.attn.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc1.bias: torch.Size([1536])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc2.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.1.attn.qkv.weight: torch.Size([1152, 384])\n",
      "partial_pcd_embedder.blocks.1.attn.qkv.bias: torch.Size([1152])\n",
      "partial_pcd_embedder.blocks.1.attn.proj.weight: torch.Size([384, 384])\n",
      "partial_pcd_embedder.blocks.1.attn.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc1.bias: torch.Size([1536])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc2.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.2.attn.qkv.weight: torch.Size([1152, 384])\n",
      "partial_pcd_embedder.blocks.2.attn.qkv.bias: torch.Size([1152])\n",
      "partial_pcd_embedder.blocks.2.attn.proj.weight: torch.Size([384, 384])\n",
      "partial_pcd_embedder.blocks.2.attn.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc1.bias: torch.Size([1536])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.0.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.0.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.0.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.0.attn.proj.bias: torch.Size([384])\n",
      "blocks.0.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.0.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.0.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.0.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.0.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.0.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.0.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.0.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.0.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.0.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.1.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.1.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.1.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.1.attn.proj.bias: torch.Size([384])\n",
      "blocks.1.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.1.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.1.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.1.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.1.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.1.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.1.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.1.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.1.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.1.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.2.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.2.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.2.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.2.attn.proj.bias: torch.Size([384])\n",
      "blocks.2.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.2.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.2.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.2.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.2.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.2.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.2.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.2.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.2.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.2.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.3.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.3.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.3.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.3.attn.proj.bias: torch.Size([384])\n",
      "blocks.3.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.3.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.3.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.3.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.3.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.3.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.3.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.3.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.3.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.3.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.4.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.4.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.4.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.4.attn.proj.bias: torch.Size([384])\n",
      "blocks.4.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.4.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.4.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.4.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.4.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.4.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.4.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.4.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.4.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.4.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.5.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.5.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.5.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.5.attn.proj.bias: torch.Size([384])\n",
      "blocks.5.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.5.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.5.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.5.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.5.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.5.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.5.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.5.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.5.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.5.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.6.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.6.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.6.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.6.attn.proj.bias: torch.Size([384])\n",
      "blocks.6.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.6.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.6.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.6.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.6.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.6.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.6.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.6.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.6.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.6.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.7.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.7.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.7.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.7.attn.proj.bias: torch.Size([384])\n",
      "blocks.7.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.7.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.7.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.7.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.7.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.7.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.7.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.7.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.7.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.7.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.8.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.8.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.8.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.8.attn.proj.bias: torch.Size([384])\n",
      "blocks.8.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.8.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.8.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.8.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.8.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.8.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.8.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.8.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.8.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.8.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.9.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.9.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.9.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.9.attn.proj.bias: torch.Size([384])\n",
      "blocks.9.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.9.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.9.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.9.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.9.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.9.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.9.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.9.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.9.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.9.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.10.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.10.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.10.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.10.attn.proj.bias: torch.Size([384])\n",
      "blocks.10.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.10.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.10.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.10.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.10.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.10.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.10.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.10.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.10.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.10.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "blocks.11.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.11.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.11.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.11.attn.proj.bias: torch.Size([384])\n",
      "blocks.11.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.11.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.11.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.11.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.11.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.11.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.weight: torch.Size([384])\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.bias: torch.Size([384])\n",
      "blocks.11.adaptmlp.down_proj.weight: torch.Size([64, 384])\n",
      "blocks.11.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.11.adaptmlp.up_proj.weight: torch.Size([384, 64])\n",
      "blocks.11.adaptmlp.up_proj.bias: torch.Size([384])\n",
      "final_layer.linear.weight: torch.Size([192, 384])\n",
      "final_layer.linear.bias: torch.Size([192])\n",
      "final_layer.adaLN_modulation.1.weight: torch.Size([768, 384])\n",
      "final_layer.adaLN_modulation.1.bias: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_S4_partial_pcd.state_dict().items():\n",
    "    print(f\"{name}: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters:  38607168\n",
      "total parameters:  39000384\n",
      "trainable parameters after freeze:  16937472\n"
     ]
    }
   ],
   "source": [
    "# make model\n",
    "model_S4_partial_pcd = DiT(depth=12, hidden_size=384, patch_size=4, num_heads=6, adaptformer=True, partial_pcd=True)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model_S4_partial_pcd.parameters() if p.requires_grad)\n",
    "print(\"trainable parameters: \", trainable_params)\n",
    "total_params = sum(p.numel() for p in model_S4_partial_pcd.parameters())\n",
    "print(\"total parameters: \", total_params)\n",
    "\n",
    "# after freeze\n",
    "layers_to_freeze = ['partial_pcd_embedder', 'adaptmlp', 'adaLN_modulation']\n",
    "for name, param in model_S4_partial_pcd.named_parameters():\n",
    "    if all(layer_name not in name for layer_name in layers_to_freeze):\n",
    "        param.requires_grad = False\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model_S4_partial_pcd.parameters() if p.requires_grad)\n",
    "print(\"trainable parameters after freeze: \", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "  (x_embedder): PatchEmbed_Voxel(\n",
       "    (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(56, 384)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=2304, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.dit3d import DiT3D_models, DiT\n",
    "from models.dit3d_window_attn import DiT3D_models_WindAttn\n",
    "model_with_windown_atten = DiT3D_models_WindAttn['DiT-S/4'](\n",
    "   input_size=32,\n",
    "   window_size=4,\n",
    "   window_block_indexes=(0,3,6,9),\n",
    "   num_classes=55,\n",
    ")\n",
    "model_with_windown_atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiT_S_4 with out adapter trainable parameters:  32631360\n",
      "DiT_S_4 with out adapter total parameters:  32827968\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model_with_windown_atten.parameters() if p.requires_grad)\n",
    "print(\"DiT_S_4 with out adapter trainable parameters: \", trainable_params)\n",
    "total_params = sum(p.numel() for p in model_with_windown_atten.parameters())\n",
    "print(\"DiT_S_4 with out adapter total parameters: \", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size: 8\n",
      "grid_size: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "  (x_embedder): PatchEmbed_Voxel(\n",
       "    (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (partial_pcd_embedder): PartialPcdEmbedder(\n",
       "    (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
       "    (x_embedder): PatchEmbed_Voxel(\n",
       "      (proj): Conv3d(3, 384, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-2): 3 x ViTBlock(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=2304, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_windown_atten_ap = DiT3D_models_WindAttn['DiT-S/4'](\n",
    "   input_size=32,\n",
    "   window_size=4,\n",
    "   window_block_indexes=(0,3,6,9),\n",
    "   num_classes=55,\n",
    "   partial_pcd=True\n",
    "   \n",
    ")\n",
    "model_with_windown_atten_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts:  132\n",
      "the number of loaded in layer:  131\n",
      "dict_keys(['pos_embed', 'x_embedder.proj.weight', 'x_embedder.proj.bias', 't_embedder.mlp.0.weight', 't_embedder.mlp.0.bias', 't_embedder.mlp.2.weight', 't_embedder.mlp.2.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.0.adaLN_modulation.1.weight', 'blocks.0.adaLN_modulation.1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.1.adaLN_modulation.1.weight', 'blocks.1.adaLN_modulation.1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.2.adaLN_modulation.1.weight', 'blocks.2.adaLN_modulation.1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.3.adaLN_modulation.1.weight', 'blocks.3.adaLN_modulation.1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.4.adaLN_modulation.1.weight', 'blocks.4.adaLN_modulation.1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.5.adaLN_modulation.1.weight', 'blocks.5.adaLN_modulation.1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.6.adaLN_modulation.1.weight', 'blocks.6.adaLN_modulation.1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.7.adaLN_modulation.1.weight', 'blocks.7.adaLN_modulation.1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.8.adaLN_modulation.1.weight', 'blocks.8.adaLN_modulation.1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.9.adaLN_modulation.1.weight', 'blocks.9.adaLN_modulation.1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.10.adaLN_modulation.1.weight', 'blocks.10.adaLN_modulation.1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'blocks.11.adaLN_modulation.1.weight', 'blocks.11.adaLN_modulation.1.bias', 'final_layer.linear.weight', 'final_layer.linear.bias', 'final_layer.adaLN_modulation.1.weight', 'final_layer.adaLN_modulation.1.bias'])\n"
     ]
    }
   ],
   "source": [
    "model_with_windown_atten_ap_dict = model_with_windown_atten_ap.state_dict()\n",
    "\n",
    "count = 0\n",
    "\n",
    "pretrained_dict = {}\n",
    "for k, v in ckpt.items():\n",
    "    if k.replace('model.module.','') in model_with_windown_atten_ap_dict and (v.shape == model_with_windown_atten_ap_dict[k.replace('model.module.','')].shape):\n",
    "        # if 'adaLN_modulation.1.weight' in k or 'adaLN_modulation.1.bias' in k:\n",
    "        #     continue\n",
    "        pretrained_dict[k.replace('model.module.','')] = v\n",
    "    count += 1\n",
    "print(\"counts: \", count)\n",
    "print(\"the number of loaded in layer: \", len(pretrained_dict))\n",
    "print(pretrained_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_windown_atten_ap_dict.update(pretrained_dict)\n",
    "model_with_windown_atten_ap.load_state_dict(model_with_windown_atten_ap_dict, strict=True)\n",
    "\n",
    "new_model_dict = model_with_windown_atten_ap.state_dict()\n",
    "\n",
    "# check loaded layers\n",
    "count = 0\n",
    "for k, v in pretrained_dict.items():\n",
    "    if torch.equal(v.to('cpu'), new_model_dict[k].to('cpu')):\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_embed: torch.Size([1, 512, 384])\n",
      "x_embedder.proj.weight: torch.Size([384, 3, 4, 4, 4])\n",
      "x_embedder.proj.bias: torch.Size([384])\n",
      "t_embedder.mlp.0.weight: torch.Size([384, 256])\n",
      "t_embedder.mlp.0.bias: torch.Size([384])\n",
      "t_embedder.mlp.2.weight: torch.Size([384, 384])\n",
      "t_embedder.mlp.2.bias: torch.Size([384])\n",
      "partial_pcd_embedder.pos_embed: torch.Size([1, 512, 384])\n",
      "partial_pcd_embedder.x_embedder.proj.weight: torch.Size([384, 3, 4, 4, 4])\n",
      "partial_pcd_embedder.x_embedder.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.0.attn.qkv.weight: torch.Size([1152, 384])\n",
      "partial_pcd_embedder.blocks.0.attn.qkv.bias: torch.Size([1152])\n",
      "partial_pcd_embedder.blocks.0.attn.proj.weight: torch.Size([384, 384])\n",
      "partial_pcd_embedder.blocks.0.attn.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc1.bias: torch.Size([1536])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "partial_pcd_embedder.blocks.0.mlp.fc2.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.1.attn.qkv.weight: torch.Size([1152, 384])\n",
      "partial_pcd_embedder.blocks.1.attn.qkv.bias: torch.Size([1152])\n",
      "partial_pcd_embedder.blocks.1.attn.proj.weight: torch.Size([384, 384])\n",
      "partial_pcd_embedder.blocks.1.attn.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc1.bias: torch.Size([1536])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "partial_pcd_embedder.blocks.1.mlp.fc2.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.2.attn.qkv.weight: torch.Size([1152, 384])\n",
      "partial_pcd_embedder.blocks.2.attn.qkv.bias: torch.Size([1152])\n",
      "partial_pcd_embedder.blocks.2.attn.proj.weight: torch.Size([384, 384])\n",
      "partial_pcd_embedder.blocks.2.attn.proj.bias: torch.Size([384])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc1.bias: torch.Size([1536])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "partial_pcd_embedder.blocks.2.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.0.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.0.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.0.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.0.attn.proj.bias: torch.Size([384])\n",
      "blocks.0.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.0.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.0.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.0.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.0.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.0.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.0.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.0.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.0.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.0.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.0.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.1.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.1.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.1.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.1.attn.proj.bias: torch.Size([384])\n",
      "blocks.1.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.1.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.1.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.1.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.1.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.1.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.1.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.1.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.1.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.1.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.1.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.2.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.2.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.2.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.2.attn.proj.bias: torch.Size([384])\n",
      "blocks.2.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.2.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.2.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.2.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.2.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.2.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.2.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.2.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.2.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.2.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.2.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.3.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.3.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.3.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.3.attn.proj.bias: torch.Size([384])\n",
      "blocks.3.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.3.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.3.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.3.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.3.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.3.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.3.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.3.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.3.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.3.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.3.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.4.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.4.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.4.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.4.attn.proj.bias: torch.Size([384])\n",
      "blocks.4.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.4.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.4.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.4.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.4.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.4.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.4.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.4.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.4.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.4.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.4.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.5.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.5.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.5.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.5.attn.proj.bias: torch.Size([384])\n",
      "blocks.5.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.5.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.5.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.5.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.5.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.5.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.5.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.5.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.5.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.5.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.5.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.6.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.6.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.6.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.6.attn.proj.bias: torch.Size([384])\n",
      "blocks.6.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.6.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.6.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.6.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.6.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.6.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.6.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.6.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.6.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.6.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.6.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.7.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.7.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.7.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.7.attn.proj.bias: torch.Size([384])\n",
      "blocks.7.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.7.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.7.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.7.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.7.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.7.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.7.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.7.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.7.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.7.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.7.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.8.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.8.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.8.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.8.attn.proj.bias: torch.Size([384])\n",
      "blocks.8.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.8.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.8.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.8.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.8.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.8.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.8.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.8.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.8.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.8.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.8.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.9.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.9.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.9.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.9.attn.proj.bias: torch.Size([384])\n",
      "blocks.9.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.9.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.9.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.9.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.9.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.9.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.9.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.9.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.9.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.9.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.9.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.10.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.10.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.10.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.10.attn.proj.bias: torch.Size([384])\n",
      "blocks.10.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.10.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.10.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.10.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.10.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.10.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.10.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.10.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.10.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.10.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.10.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "blocks.11.attn.qkv.weight: torch.Size([1152, 384])\n",
      "blocks.11.attn.qkv.bias: torch.Size([1152])\n",
      "blocks.11.attn.proj.weight: torch.Size([384, 384])\n",
      "blocks.11.attn.proj.bias: torch.Size([384])\n",
      "blocks.11.mlp.fc1.weight: torch.Size([1536, 384])\n",
      "blocks.11.mlp.fc1.bias: torch.Size([1536])\n",
      "blocks.11.mlp.fc2.weight: torch.Size([384, 1536])\n",
      "blocks.11.mlp.fc2.bias: torch.Size([384])\n",
      "blocks.11.adaLN_modulation.1.weight: torch.Size([2304, 384])\n",
      "blocks.11.adaLN_modulation.1.bias: torch.Size([2304])\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.weight: torch.Size([1152])\n",
      "blocks.11.adaptmlp.adapter_layer_norm_before.bias: torch.Size([1152])\n",
      "blocks.11.adaptmlp.down_proj.weight: torch.Size([64, 1152])\n",
      "blocks.11.adaptmlp.down_proj.bias: torch.Size([64])\n",
      "blocks.11.adaptmlp.up_proj.weight: torch.Size([1152, 64])\n",
      "blocks.11.adaptmlp.up_proj.bias: torch.Size([1152])\n",
      "final_layer.linear.weight: torch.Size([192, 384])\n",
      "final_layer.linear.bias: torch.Size([192])\n",
      "final_layer.adaLN_modulation.1.weight: torch.Size([768, 384])\n",
      "final_layer.adaLN_modulation.1.bias: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_with_windown_atten_ap.state_dict().items():\n",
    "    print(f\"{name}: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda-11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
